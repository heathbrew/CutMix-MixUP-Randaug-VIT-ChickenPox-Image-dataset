{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3225f170-7e0c-4319-8d51-a5a8b423dbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 614\n",
      "Image shape: (128, 128)\n",
      "Number of classes: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\templ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import os\n",
    "\n",
    "# # Define the directory containing the leaf images\n",
    "# data_dir = 'workingSplitMonkeypoxSkinImageDataset/train'\n",
    "\n",
    "# # Define the size of the images after preprocessing\n",
    "# img_size = (128, 128)\n",
    "\n",
    "# # Define a function to preprocess the images\n",
    "# def preprocess_image(img_path):\n",
    "#     # Load the image from disk\n",
    "#     img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     # Resize the image to a fixed size\n",
    "#     img = cv2.resize(img, img_size)\n",
    "#     # Normalize the pixel values to [0, 1]\n",
    "#     img = img.astype('float32') / 255.0\n",
    "#     return img\n",
    "\n",
    "\n",
    "# # Create a list of all the subdirectories in the directory that have images in them\n",
    "# subdirs = []\n",
    "# for dname in os.listdir(data_dir):\n",
    "#     subdir = os.path.join(data_dir, dname)\n",
    "#     if os.path.isdir(subdir) and len(os.listdir(subdir)) > 0:\n",
    "#         subdirs.append(subdir)\n",
    "\n",
    "# # Create an empty list to store the preprocessed images\n",
    "# X = []\n",
    "# # Create an empty list to store the labels\n",
    "# y = []\n",
    "\n",
    "# # Loop over each subdirectory and its contents and preprocess each image\n",
    "# for i, subdir in enumerate(subdirs):\n",
    "#     for fname in os.listdir(subdir):\n",
    "#         if fname.endswith('.png'):\n",
    "#             # Preprocess the image\n",
    "#             img_path = os.path.join(subdir, fname)\n",
    "#             img = preprocess_image(img_path)\n",
    "#             # Append the preprocessed image and label to the lists\n",
    "#             X.append(img)\n",
    "#             y.append(i) # Use the index of the subdirectory as the label\n",
    "#             # Save the preprocessed image to disk\n",
    "#             new_fname = fname.replace('.png', '_preprocessed.png')\n",
    "#             new_path = os.path.join(subdir, new_fname)\n",
    "#             cv2.imwrite(new_path, img * 255.0)\n",
    "#             # Delete the original image\n",
    "#             os.remove(img_path)\n",
    "\n",
    "# # Convert the lists to numpy arrays\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "# # Convert the labels to one-hot encoded vectors\n",
    "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_encoded = label_encoder.fit_transform(y)\n",
    "# onehot_encoder = OneHotEncoder(sparse=False)\n",
    "# y_onehot = onehot_encoder.fit_transform(y_encoded.reshape(-1, 1))\n",
    "\n",
    "# # Print some basic statistics about the data\n",
    "# print('Number of images:', len(X))\n",
    "# print('Image shape:', X.shape[1:])\n",
    "# print('Number of classes:', y_onehot.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18fdc1a4-4e04-4a20-a1c1-94155bb0a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import os\n",
    "\n",
    "# # Define the directory containing the leaf images\n",
    "# data_dir = 'workingSplitMonkeypoxSkinImageDataset/train'\n",
    "\n",
    "# # Define the size of the images after preprocessing\n",
    "# img_size = (128, 128)\n",
    "\n",
    "# # Define a function to preprocess the images\n",
    "# def preprocess_image(img_path):\n",
    "#     # Load the image from disk\n",
    "#     img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     # Resize the image to a fixed size\n",
    "#     img = cv2.resize(img, img_size)\n",
    "#     # Normalize the pixel values to [0, 1]\n",
    "#     img = img.astype('float32') / 255.0\n",
    "#     return img\n",
    "\n",
    "# # Convert JPEG to PNG\n",
    "# def convert_to_png(img_path):\n",
    "#     img = Image.open(img_path)\n",
    "#     new_path = img_path.replace('.jpg', '.png')\n",
    "#     img.save(new_path)\n",
    "#     return new_path\n",
    "\n",
    "# # Create a list of all the subdirectories in the directory that have images in them\n",
    "# subdirs = []\n",
    "# for dname in os.listdir(data_dir):\n",
    "#     subdir = os.path.join(data_dir, dname)\n",
    "#     if os.path.isdir(subdir) and len(os.listdir(subdir)) > 0:\n",
    "#         subdirs.append(subdir)\n",
    "\n",
    "# # Create an empty list to store the preprocessed images\n",
    "# X = []\n",
    "# # Create an empty list to store the labels\n",
    "# y = []\n",
    "\n",
    "# # Loop over each subdirectory and its contents and convert each JPEG image to PNG\n",
    "# # and preprocess each image\n",
    "# for i, subdir in enumerate(subdirs):\n",
    "#     for fname in os.listdir(subdir):\n",
    "#         if fname.endswith('.jpg'):\n",
    "#             # Convert the image to PNG\n",
    "#             img_path = os.path.join(subdir, fname)\n",
    "#             img_path = convert_to_png(img_path)\n",
    "#         elif fname.endswith('.png'):\n",
    "#             img_path = os.path.join(subdir, fname)\n",
    "#         else:\n",
    "#             continue\n",
    "#         # Preprocess the image and apply cutmix augmentation\n",
    "#         img, label = preprocess_image(img_path, i, apply_cutmix=True)\n",
    "#         # Append the preprocessed image and label to the lists\n",
    "#         X.append(img)\n",
    "#         y.append(label) # Use the index of the subdirectory as the label\n",
    "#         # Save the preprocessed image to disk\n",
    "#         new_fname = os.path.basename(img_path).replace('.png', '_preprocessed.png')\n",
    "#         new_path = os.path.join(subdir, new_fname)\n",
    "#         cv2.imwrite(new_path, img * 255.0)\n",
    "#         # Delete the original image\n",
    "#         os.remove(img_path)\n",
    "\n",
    "\n",
    "# # Convert the lists to numpy arrays\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "# # Convert the labels to one-hot encoded vectors\n",
    "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_encoded = label_encoder.fit_transform(y)\n",
    "# onehot_encoder = OneHotEncoder(sparse=False)\n",
    "# y_onehot = onehot_encoder.fit_transform(y_encoded.reshape(-1, 1))\n",
    "\n",
    "# # Print some basic statistics about the data\n",
    "# print('Number of images:', len(X))\n",
    "# print('Image shape:', X.shape[1:])\n",
    "# print('Number of classes:', y_onehot.shape[1])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e68b188-7256-4699-a93d-32f1e8d9c03c",
   "metadata": {},
   "source": [
    "CutMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6a56630-791d-4615-91ca-81d8e476e597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 75\n",
      "Image shape: (128, 128, 3)\n",
      "Number of classes: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\templ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Define the directory containing the leaf images\n",
    "data_dir = 'CutmixSplitMonkeypoxSkinImageDataset/val'\n",
    "\n",
    "# Define the size of the images after preprocessing and augmentation\n",
    "img_size = (128, 128)\n",
    "\n",
    "# Define the cutmix parameters\n",
    "beta = 1  # the hyperparameter for the beta distribution\n",
    "cutmix_prob = 0.5  # the probability of applying cutmix\n",
    "\n",
    "# Define a function to apply cutmix augmentation to a pair of images\n",
    "def cutmix(images, labels):\n",
    "    # Select two random images and labels\n",
    "    idx = np.random.choice(len(images), 2, replace=False)\n",
    "    img1, img2 = np.take(images, idx, axis=0)\n",
    "    label1, label2 = np.take(labels, idx, axis=0)\n",
    "    # Get the dimensions of the images\n",
    "    h, w = img1.shape[:2]\n",
    "    # Choose a random point to cut the images\n",
    "    cut_x = random.randint(0, w)\n",
    "    cut_y = random.randint(0, h)\n",
    "    # Create the mixed image\n",
    "    mixed_img = np.zeros_like(img1)\n",
    "    mixed_img[:cut_y, :cut_x] = img1[:cut_y, :cut_x]\n",
    "    mixed_img[cut_y:, cut_x:] = img2[cut_y:, cut_x:]\n",
    "    # Create the mixed label\n",
    "    mixed_label = label1 * (cut_x * cut_y / (w * h)) + label2 * ((w - cut_x) * (h - cut_y) / (w * h))\n",
    "    return mixed_img, mixed_label\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to preprocess the images and apply cutmix augmentation\n",
    "def preprocess_image(img_path, label, apply_cutmix=True):\n",
    "    # Load the image from disk\n",
    "    img = cv2.imread(img_path, cv2.COLOR_BGR2RGB)\n",
    "    # Resize the image to a fixed size\n",
    "    img = cv2.resize(img, img_size)\n",
    "    # Normalize the pixel values to [0, 1]\n",
    "    img = img.astype('float32') / 255.0\n",
    "    # Apply cutmix augmentation with a certain probability\n",
    "    if apply_cutmix and random.random() < cutmix_prob and len(X) > 0:\n",
    "        # Choose another image and label to mix with\n",
    "        mix_idx = random.randrange(len(X))\n",
    "        mixed_img, mixed_label = cutmix([img, X[mix_idx]], [label, y[mix_idx]])\n",
    "        return mixed_img, mixed_label\n",
    "    else:\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# Create a list of all the subdirectories in the directory that have images in them\n",
    "subdirs = []\n",
    "for dname in os.listdir(data_dir):\n",
    "    subdir = os.path.join(data_dir, dname)\n",
    "    if os.path.isdir(subdir) and len(os.listdir(subdir)) > 0:\n",
    "        subdirs.append(subdir)\n",
    "\n",
    "# Create an empty list to store the preprocessed images\n",
    "X = []\n",
    "# Create an empty list to store the labels\n",
    "y = []\n",
    "\n",
    "# Loop over each subdirectory and its contents and convert each JPEG image to PNG\n",
    "# and preprocess each image\n",
    "for i, subdir in enumerate(subdirs):\n",
    "    for fname in os.listdir(subdir):\n",
    "        if fname.endswith('.jpg'):\n",
    "            # Convert the image to PNG\n",
    "            img_path = os.path.join(subdir, fname)\n",
    "            img_path = convert_to_png(img_path)\n",
    "        elif fname.endswith('.png'):\n",
    "            img_path = os.path.join(subdir, fname)\n",
    "        else:\n",
    "            continue\n",
    "        # Preprocess the image and apply cutmix augmentation\n",
    "        img, label = preprocess_image(img_path, i, apply_cutmix=True)\n",
    "        # Append the preprocessed image and label to the lists\n",
    "        X.append(img)\n",
    "        y.append(label) # Use the index of the subdirectory as the label\n",
    "        # Save the preprocessed image to disk\n",
    "        new_fname = os.path.basename(img_path).replace('.png', '_preprocessed.png')\n",
    "        new_path = os.path.join(subdir, new_fname)\n",
    "        cv2.imwrite(new_path, img * 255.0)\n",
    "        # Delete the original image\n",
    "        os.remove(img_path)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Convert the labels to one-hot encoded vectors\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = onehot_encoder.fit_transform(y_encoded.reshape(-1, 1))\n",
    "\n",
    "# Print some basic statistics about the data\n",
    "print('Number of images:', len(X))\n",
    "print('Image shape:', X.shape[1:])\n",
    "print('Number of classes:', y_onehot.shape[1])        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de627f43-8a60-416b-ba52-d8eaa0e1a9fa",
   "metadata": {},
   "source": [
    "Mixup augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0ce0755-d140-4b37-aae1-97fa3b478251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 614\n",
      "Image shape: (128, 128, 3)\n",
      "Number of classes: 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\templ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Define the directory containing the leaf images\n",
    "data_dir = 'MixupSplitMonkeypoxSkinImageDataset/train'\n",
    "\n",
    "# Define the size of the images after preprocessing and augmentation\n",
    "img_size = (128, 128)\n",
    "\n",
    "# Define the cutmix parameters\n",
    "beta = 1  # the hyperparameter for the beta distribution\n",
    "cutmix_prob = 0.5  # the probability of applying cutmix\n",
    "\n",
    "\n",
    "# Define a function to apply mixup augmentation to a pair of images\n",
    "def mixup(images, labels, alpha=0.4):\n",
    "    # Select two random images and labels\n",
    "    idx = np.random.choice(len(images), 2, replace=False)\n",
    "    img1, img2 = np.take(images, idx, axis=0)\n",
    "    label1, label2 = np.take(labels, idx, axis=0)\n",
    "    # Get the dimensions of the images\n",
    "    h, w = img1.shape[:2]\n",
    "    \n",
    "    # Generate the mixup ratio from a beta distribution\n",
    "    mix_ratio = np.random.beta(alpha, alpha)\n",
    "\n",
    "    # Create the mixed image\n",
    "    mixed_img = mix_ratio * img1 + (1 - mix_ratio) * img2\n",
    "\n",
    "    # Create the mixed label\n",
    "    mixed_label = mix_ratio * label1 + (1 - mix_ratio) * label2\n",
    "    \n",
    "    return mixed_img, mixed_label\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to preprocess the images and apply cutmix augmentation\n",
    "def preprocess_image(img_path, label, apply_cutmix=True):\n",
    "    # Load the image from disk\n",
    "    img = cv2.imread(img_path, cv2.COLOR_BGR2RGB)\n",
    "    # Resize the image to a fixed size\n",
    "    img = cv2.resize(img, img_size)\n",
    "    # Normalize the pixel values to [0, 1]\n",
    "    img = img.astype('float32') / 255.0\n",
    "    # Apply cutmix augmentation with a certain probability\n",
    "    # Apply mixup augmentation with a certain probability\n",
    "    if apply_cutmix and random.random() < cutmix_prob and len(X) > 0:\n",
    "        # Choose another image and label to mix with\n",
    "        mix_idx = random.randrange(len(X))\n",
    "        mixed_img, mixed_label = mixup([img, X[mix_idx]], [label, y[mix_idx]])\n",
    "        return mixed_img, mixed_label\n",
    "    else:\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# Create a list of all the subdirectories in the directory that have images in them\n",
    "subdirs = []\n",
    "for dname in os.listdir(data_dir):\n",
    "    subdir = os.path.join(data_dir, dname)\n",
    "    if os.path.isdir(subdir) and len(os.listdir(subdir)) > 0:\n",
    "        subdirs.append(subdir)\n",
    "\n",
    "# Create an empty list to store the preprocessed images\n",
    "X = []\n",
    "# Create an empty list to store the labels\n",
    "y = []\n",
    "\n",
    "# Loop over each subdirectory and its contents and convert each JPEG image to PNG\n",
    "# and preprocess each image\n",
    "for i, subdir in enumerate(subdirs):\n",
    "    for fname in os.listdir(subdir):\n",
    "        if fname.endswith('.jpg'):\n",
    "            # Convert the image to PNG\n",
    "            img_path = os.path.join(subdir, fname)\n",
    "            img_path = convert_to_png(img_path)\n",
    "        elif fname.endswith('.png'):\n",
    "            img_path = os.path.join(subdir, fname)\n",
    "        else:\n",
    "            continue\n",
    "        # Preprocess the image and apply cutmix augmentation\n",
    "        img, label = preprocess_image(img_path, i, apply_cutmix=True)\n",
    "        # Append the preprocessed image and label to the lists\n",
    "        X.append(img)\n",
    "        y.append(label) # Use the index of the subdirectory as the label\n",
    "        # Save the preprocessed image to disk\n",
    "        new_fname = os.path.basename(img_path).replace('.png', '_preprocessed.png')\n",
    "        new_path = os.path.join(subdir, new_fname)\n",
    "        cv2.imwrite(new_path, img * 255.0)\n",
    "        # Delete the original image\n",
    "        os.remove(img_path)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Convert the labels to one-hot encoded vectors\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = onehot_encoder.fit_transform(y_encoded.reshape(-1, 1))\n",
    "\n",
    "# Print some basic statistics about the data\n",
    "print('Number of images:', len(X))\n",
    "print('Image shape:', X.shape[1:])\n",
    "print('Number of classes:', y_onehot.shape[1])        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5634a68-17ca-43a7-853b-3865b1233223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imgaug\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "                                              0.0/948.0 kB ? eta -:--:--\n",
      "                                              10.2/948.0 kB ? eta -:--:--\n",
      "     ---                                     92.2/948.0 kB 1.1 MB/s eta 0:00:01\n",
      "     --------                               204.8/948.0 kB 1.8 MB/s eta 0:00:01\n",
      "     --------                               204.8/948.0 kB 1.8 MB/s eta 0:00:01\n",
      "     -----------------                      440.3/948.0 kB 2.0 MB/s eta 0:00:01\n",
      "     ------------------------------         757.8/948.0 kB 3.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 948.0/948.0 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imgaug) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imgaug) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imgaug) (1.10.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imgaug) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imgaug) (3.6.3)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imgaug) (0.20.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imgaug) (4.7.0.72)\n",
      "Requirement already satisfied: imageio in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imgaug) (2.25.0)\n",
      "Collecting Shapely (from imgaug)\n",
      "  Downloading shapely-2.0.1-cp310-cp310-win_amd64.whl (1.4 MB)\n",
      "                                              0.0/1.4 MB ? eta -:--:--\n",
      "     ---------                                0.3/1.4 MB 6.8 MB/s eta 0:00:01\n",
      "     -------------------------                0.9/1.4 MB 9.2 MB/s eta 0:00:01\n",
      "     --------------------------------------   1.3/1.4 MB 10.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.3/1.4 MB 8.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.4/1.4 MB 6.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (23.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image>=0.14.2->imgaug) (0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->imgaug) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->imgaug) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->imgaug) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->imgaug) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->imgaug) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->imgaug) (2.8.2)\n",
      "Installing collected packages: Shapely, imgaug\n",
      "Successfully installed Shapely-2.0.1 imgaug-0.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -egex (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -egex (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install imgaug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f41a545-1dd3-4fbc-b2d9-22210dfc0aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Using cached albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: numpy>=1.11.1 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from albumentations) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from albumentations) (1.10.0)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from albumentations) (0.20.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from albumentations) (6.0)\n",
      "Collecting qudida>=0.0.4 (from albumentations)\n",
      "  Using cached qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting opencv-python-headless>=4.1.1 (from albumentations)\n",
      "  Using cached opencv_python_headless-4.7.0.72-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from qudida>=0.0.4->albumentations) (1.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (3.0)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.25.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (23.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (0.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Installing collected packages: opencv-python-headless, qudida, albumentations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -egex (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -aiss-cpu (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -egex (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\templ\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\templ\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a129ead9-a8fc-4d86-9ba8-f4e74230287f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 613\n",
      "Image shape: (128, 128)\n",
      "Number of classes: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\templ\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Define the directory containing the leaf images\n",
    "data_dir = 'RandaugmentSplitMonkeypoxSkinImageDataset/train'\n",
    "\n",
    "# Define the size of the images after preprocessing\n",
    "img_size = (128, 128)\n",
    "\n",
    "# Define a function to preprocess the images\n",
    "def preprocess_image(img_path, apply_augmentation=True):\n",
    "    # Load the image from disk\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Resize the image to a fixed size\n",
    "    img = cv2.resize(img, img_size)\n",
    "    # Normalize the pixel values to [0, 1]\n",
    "    img = img.astype('float32') / 255.0\n",
    "    \n",
    "    if apply_augmentation:\n",
    "        # Randomly flip the image horizontally\n",
    "        if random.random() < 0.5:\n",
    "            img = cv2.flip(img, 1)\n",
    "        \n",
    "        # Randomly adjust the brightness of the image\n",
    "        brightness = random.uniform(0.7, 1.3)\n",
    "        img = cv2.convertScaleAbs(img, alpha=brightness, beta=0)\n",
    "        \n",
    "        # Randomly adjust the contrast of the image\n",
    "        contrast = random.uniform(0.7, 1.3)\n",
    "        img_mean = np.mean(img)\n",
    "        img = cv2.convertScaleAbs(img, alpha=contrast, beta=img_mean*(1-contrast))\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Convert JPEG to PNG\n",
    "def convert_to_png(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    new_path = img_path.replace('.jpg', '.png')\n",
    "    img.save(new_path)\n",
    "    return new_path\n",
    "\n",
    "# Create a list of all the subdirectories in the directory that have images in them\n",
    "subdirs = []\n",
    "for dname in os.listdir(data_dir):\n",
    "    subdir = os.path.join(data_dir, dname)\n",
    "    if os.path.isdir(subdir) and len(os.listdir(subdir)) > 0:\n",
    "        subdirs.append(subdir)\n",
    "\n",
    "# Create an empty list to store the preprocessed images\n",
    "X = []\n",
    "# Create an empty list to store the labels\n",
    "y = []\n",
    "\n",
    "# Loop over each subdirectory and its contents and convert each JPEG image to PNG\n",
    "# and preprocess each image with random augmentation simulation\n",
    "for i, subdir in enumerate(subdirs):\n",
    "    for fname in os.listdir(subdir):\n",
    "        if fname.endswith('.jpg'):\n",
    "            # Convert the image to PNG\n",
    "            img_path = os.path.join(subdir, fname)\n",
    "            img_path = convert_to_png(img_path)\n",
    "        elif fname.endswith('.png'):\n",
    "            img_path = os.path.join(subdir, fname)\n",
    "        else:\n",
    "            continue\n",
    "        # Preprocess the image with random augmentation simulation\n",
    "        img = preprocess_image(img_path, apply_augmentation=True)\n",
    "        # Append the preprocessed image and label to the lists\n",
    "        X.append(img)\n",
    "        y.append(i) # Use the index of the subdirectory as the label\n",
    "        # Save the preprocessed image to disk\n",
    "        new_fname = os.path.basename(img_path).replace('.png', '_preprocessed.png')\n",
    "        new_path = os.path.join(subdir, new_fname)\n",
    "        cv2.imwrite(new_path, img * 255.0)\n",
    "        # Delete the original image\n",
    "        os.remove(img_path)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Convert the labels to one-hot encoded vectors\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = onehot_encoder.fit_transform(y_encoded.reshape(-1, 1))\n",
    "\n",
    "# Print some basic\n",
    "# Print some basic statistics about the data\n",
    "print('Number of images:', len(X))\n",
    "print('Image shape:', X.shape[1:])\n",
    "print('Number of classes:', y_onehot.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1c886-2156-4440-9988-b40e388fe47b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
